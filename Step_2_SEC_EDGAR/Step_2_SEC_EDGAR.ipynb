{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fac7c-be15-4b0a-9e2d-6946c0e04104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sec_api import ExtractorApi\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174afeb-ac1d-4487-80cd-58c38ad19232",
   "metadata": {},
   "source": [
    "# 2. Data Collection from SEC EDGAR System to get Corprate 10-K filings:\n",
    "\n",
    "Link to sec-api.io : https://sec-api.io/docs/sec-filings-item-extraction-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490ea77-ba22-45bd-acc7-56097800fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents_info = pd.read_csv('company_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1774e9-5d34-4217-8096-ab21b0ad7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryApi = QueryApi(api_key=\" Insert API key here\")\n",
    "extractorApi = ExtractorApi(\" Insert API key here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2192a1-f6c7-40ed-9f62-c1fc24b5c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df_documents_info_cleaned` is your DataFrame containing the URLs and metadata\n",
    "documents_info = []\n",
    "\n",
    "for index, row in tqdm(df_documents_info_cleaned.iterrows(), total=df_documents_info_cleaned.shape[0], desc=\"Fetching and Cleaning Documents\"):\n",
    "    # Extract necessary information from the row\n",
    "    ticker = row['ticker']\n",
    "    filedAt = row['filedAt']\n",
    "    sector = row['sector']\n",
    "    filing_url = row['linkToFilingDetails']\n",
    "    \n",
    "    # Fetch the document text for both sections 1 and 1A\n",
    "    section_1_text = extractorApi.get_section(filing_url, \"1\", \"text\")\n",
    "    section_1A_text = extractorApi.get_section(filing_url, \"1A\", \"text\")\n",
    "    \n",
    "    # Combine both sections' texts\n",
    "    combined_text = section_1_text + \" \" + section_1A_text  # Ensure there's a space between the two sections\n",
    "    \n",
    "    # Clean the combined section text\n",
    "    cleaned_combined_section = re.sub(r\"\\n|&#[0-9]+;\", \"\", combined_text)\n",
    "    \n",
    "    # Append a dictionary for each document containing its metadata and cleaned combined text\n",
    "    documents_info.append({\n",
    "        'ticker': ticker,\n",
    "        'filedAt': filedAt,\n",
    "        'sector': sector,\n",
    "        'text': cleaned_combined_section\n",
    "    })\n",
    "\n",
    "# Serialize the list of dictionaries to a file using pickle\n",
    "with open('Cleaned_US_Item1_1A.pkl', 'wb') as f:\n",
    "    pickle.dump(documents_info, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
